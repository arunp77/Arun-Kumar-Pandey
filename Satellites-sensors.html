<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Portfolio Details</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/Favicon-1.png" rel="icon">
  <link href="assets/img/Favicon-1.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">
  <!-- Creating a python code section-->
  <link rel="stylesheet" href="assets/css/prism.css">
  <script src="assets/js/prism.js"></script>

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- To set the icon, visit https://fontawesome.com/account-->
  <script src="https://kit.fontawesome.com/5d25c1efd3.js" crossorigin="anonymous"></script>
  <!-- end of icon-->

  <!-- =======================================================
  * Template Name: iPortfolio
  * Updated: Sep 18 2023 with Bootstrap v5.3.2
  * Template URL: https://bootstrapmade.com/iportfolio-bootstrap-portfolio-websites-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Mobile nav toggle button ======= -->
  <i class="bi bi-list mobile-nav-toggle d-xl-none"></i>

  <!-- ======= Header ======= -->
  <header id="header">
    <div class="d-flex flex-column">

      <div class="profile">
        <img src="assets/img/myphoto.jpeg" alt="" class="img-fluid rounded-circle">
        <h1 class="text-light"><a href="index.html">Arun</a></h1>
        <div class="social-links mt-3 text-center">
          <a href="https://www.linkedin.com/in/arunp77/" class="linkedin"><i class="bx bxl-linkedin"></i></a>
          <a href="https://github.com/arunp77" class="github"><i class="bx bxl-github"></i></a>
          <a href="https://twitter.com/arunp77_" class="twitter"><i class="bx bxl-twitter"></i></a>
          <a href="https://www.instagram.com/arunp77/" class="instagram"><i class="bx bxl-instagram"></i></a>
          <a href="https://medium.com/@arunp77" class="medium"><i class="bx bxl-medium"></i></a>
        </div>
      </div>

      <nav id="navbar" class="nav-menu navbar">
        <ul>
          <li><a href="index.html#hero" class="nav-link scrollto active"><i class="bx bx-home"></i> <span>Home</span></a></li>
          <li><a href="index.html#about" class="nav-link scrollto"><i class="bx bx-user"></i> <span>About</span></a></li>
          <li><a href="index.html#skills-and-tools" class="nav-link scrollto"><i class="bx bx-wrench"></i> <span>Skills and Tools</span></a></li>
          <li><a href="index.html#resume" class="nav-link scrollto"><i class="bx bx-file-blank"></i> <span>Resume</span></a></li>
          <li><a href="index.html#portfolio" class="nav-link scrollto"><i class="bx bx-book-content"></i> <span>Portfolio</span></a></li>
          <li><a href="index.html#services" class="nav-link scrollto"><i class="bx bx-server"></i> <span>Services</span></a></li>
          <li><a href="index.html#professionalcourses" class="nav-link scrollto"><i class="bx bx-book-alt"></i> <span>Professional Certification</span></a></li>
          <li><a href="index.html#publications" class="nav-link scrollto"><i class="bx bx-news"></i> <span>Publications</span></a></li>
          <li><a href="index.html#extra-curricular" class="nav-link scrollto"><i class="bx bx-rocket"></i> <span>Extra-Curricular Activities</span></a></li>
          <li><a href="index.html#contact" class="nav-link scrollto"><i class="bx bx-envelope"></i> <span>Contact</span></a></li>
        </ul>
      </nav><!-- .nav-menu -->
    </div>
  </header><!-- End Header -->

<main id="main">

    <!-- ======= Breadcrumbs ======= -->
    <section id="breadcrumbs" class="breadcrumbs">
      <div class="container">

        <div class="d-flex justify-content-between align-items-center">
          <h2>Portfolio Details</h2>
          <ol>
            <li><a href="Remote-sensing-content.html" class="clickable-box"><i class="fas fa-arrow-left"></i> Content </a></li>
            <li><a href="index.html" class="clickable-box">Home <i class="fas fa-arrow-right"></i></a></li>
          </ol>
        </div>

      </div>
    </section><!-- End Breadcrumbs -->

    <!------  right dropdown menue ------->
    <div class="right-side-list">
      <div class="dropdown">
          <button class="dropbtn"><strong>Shorcuts:</strong></button>
          <div class="dropdown-content">
              <ul>
                  <li><a href="cloud-compute.html"><i class="fas fa-cloud"></i> Cloud</a></li>
                  <li><a href="AWS-GCP.html"><i class="fas fa-cloud"></i> AWS-GCP</a></li>
                  <li><a href="amazon-s3.html"><i class="fas fa-cloud"></i> AWS S3</a></li>
                  <li><a href="ec2-confi.html"><i class="fas fa-server"></i> EC2</a></li>
                  <li><a href="Docker-Container.html"><i class="fab fa-docker" style="color: rgb(22, 22, 22);"></i> Docker</a></li>
                  <li><a href="Jupyter-nifi.html"><i class="fab fa-python" style="color: rgb(15, 15, 15);"></i> Jupyter-nifi</a></li>
                  <li><a href="snowflake-task-stream.html"><i class="fas fa-snowflake"></i> Snowflake</a></li>
                  <li><a href="data-model.html"><i class="fas fa-database"></i> Data modeling</a></li>
                  <li><a href="sql-basics.html"><i class="fas fa-table"></i> QL</a></li>
                  <li><a href="sql-basic-details.html"><i class="fas fa-database"></i> SQL</a></li>
                  <li><a href="Bigquerry-sql.html"><i class="fas fa-database"></i> Bigquerry</a></li>
                  <li><a href="scd.html"><i class="fas fa-archive"></i> SCD</a></li>
                  <li><a href="sql-project.html"><i class="fas fa-database"></i> SQL project</a></li>
                    <!-- Add more subsections as needed -->
                </ul>
          </div>
      </div>
  </div>

    <!-- ======= Portfolio Details Section ======= -->
    <section id="portfolio-details" class="portfolio-details">
      <div class="container">
        <div class="row gy-4">
          <h1>Satellites and Sensors</h1>
          <div class="image">
            <figure style="text-align: center;">
                <img src="assets/img/remote-sensing/remote-dataprocessing.png" alt="" style="max-width: 80%; max-height: 80%;">
                <figcaption style="text-align: center;"><strong>Image credit:</strong><a href="https://www.mdpi.com/2072-4292/12/22/3801#" target="_blank"> Yinghui Quan et al.</a></figcaption>
            </figure>            
          </div>

          <section id="Section-1">
            <h2>Recording of energy by the sensor: </h2>
            In remote sensing, it is very important to understand the data provided by sensors in order to interpret them properly. The first thing to do is to understand what a satellite image 
            is and why it is different from a photograph. The main difference between a photograph and a satellite image is that the photograph has an analogue format and is usually printed 
            on paper before being interpreted. The satellite image has a digital format and a computer is generally used to analyse and interpret it. The evolution of remote sensing techniques 
            has witnessed a transition from traditional analog methods to the contemporary era of digital technology. A comparative table below summarizes key differences between the two.
            <table>
                <thead>
                  <tr>
                    <th>Aspect</th>
                    <th>Analog Photographs</th>
                    <th>Digital Images</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>Capture Method</td>
                    <td>Uses film and optical systems for capturing images.</td>
                    <td>Employs electronic sensors to directly capture digital data.</td>
                  </tr>
                  <tr>
                    <td>Resolution</td>
                    <td>Limited resolution, typically lower than digital counterparts.</td>
                    <td>Higher resolution, enabling finer detail and clarity.</td>
                  </tr>
                  <tr>
                    <td>Flexibility</td>
                    <td>Limited post-capture manipulation options.</td>
                    <td>Allows extensive post-processing for enhancement and analysis.</td>
                  </tr>
                  <tr>
                    <td>Storage</td>
                    <td>Requires physical storage space for film rolls.</td>
                    <td>Data stored digitally, facilitating easy archiving and retrieval.</td>
                  </tr>
                  <tr>
                    <td>Transmission</td>
                    <td>Time-consuming and manual distribution of physical prints.</td>
                    <td>Easily transmitted electronically for rapid sharing and analysis.</td>
                  </tr>
                  <tr>
                    <td>Cost</td>
                    <td>Lower initial costs, but ongoing expenses for film and processing.</td>
                    <td>Higher initial investment, but lower ongoing costs for storage.</td>
                  </tr>
                  <tr>
                    <td>Environmental Impact</td>
                    <td>Chemical processes in film development can be environmentally harmful.</td>
                    <td>Generally more environmentally friendly, with less chemical waste.</td>
                  </tr>
                  <tr>
                    <td>Integration with Technology</td>
                    <td>Limited integration with modern data analysis tools.</td>
                    <td>Seamless integration with advanced data science and analytics tools.</td>
                  </tr>
                </tbody>
              </table><br>
              <h4>Digital image formats</h4>
              <ul>
                <li>The distinction between analogue and digital formats lies in how they represent and store information. In the analogue format, data is continuous, seamlessly spread throughout. 
                    For instance, when you capture an image in an analogue format, there are no discernible edges between different parts of the image.</li>
                <li>On the other hand, digital format employs a different approach. It saves information in separate blocks, often referred to as <strong>pixels</strong>. When you zoom in on a digital image, you'll 
                    notice these pixels—small squares of various colors in the case of satellite imagery. This discrete representation, organized in a matrix of squares, is a key characteristic of 
                    digital formats.</li>
                    <li>The digital format relies on a mathematical process called a 'binary system.' This system is the foundation of computer operations, enabling them to register, calculate, save data, and display 
                        images. In the binary system, computers comprehend only electric pulses, translating them into a binary code of 0s and 1s. This binary language forms the basis of the entire computer world.</li>
                    <li>Mathematicians initially doubted the ability of computers to handle decimal systems, the way we traditionally count (0 to 9, then a new series from 10 to 19, and so on). However, computers 
                        operate in a binary mode, going from 0 to 1, restarting the series. It's a binary world where 'yes' or 'no,' 0 or 1, encapsulates the fundamental language of computation</li>
                        <div style="background-color: #f0f0f0; padding: 10px; border-radius: 5px;">
                            <ul>
                                <li>A group of 2 numbers (also called 'digits') is called a 'bit';</li>
                                <li>A group of 8 bits is called a 'byte' (= 256 in the decimal system);</li>
                                <li>1 Kb is equal to 1000 bytes;</li>
                                <li>1 Mb is equal to 1,000,000 bytes;</li>
                                <li>If your computer has a memory of 64Mb, this means that it can cope with data containing up to 64 × 1,000,000 × 8, that is 512,000,000 bits or electric pulses;</li>
                                <li>And if your computer has a hard disk of 2Gb, it means that it can contain data amounting to 2 × 1,000,000,000 × 8, that is 16,000,000,000 bits or electric pulses.</li>
                            </ul>
                        </div>
              </ul>
              <h4>The pixels</h4>
              In remote sensing, <strong>pixels</strong> are the smallest units of a digital image, representing specific areas on the Earth's surface. Each pixel has a numeric value reflecting the characteristics of the 
              corresponding scene, such as brightness or color. Remote sensing images are composed of a grid of pixels, and the <strong>resolution</strong> is determined by the size of these pixels. Higher <strong>resolution</strong> 
              provides more detailed images. Pixels are crucial for the digital representation, storage, and analysis of remote sensing data. <p> </p>
                <figure style="text-align: center;">
                    <img src="assets/img/remote-sensing/the-pixels.png" alt="" style="max-width: 60%; max-height: 60%;">
                    <figcaption style="text-align: center;"><strong>Image credit:</strong><a href="https://www.mdpi.com/2072-4292/9/9/967" target="_blank"> © Darius Phiri and Justin Morgenroth</a></figcaption>
                </figure><br>

            Each pixel holds a numeric value, known as a pixel value, reflecting attributes like color or brightness. In remote sensing, pixel values encode information about the observed scene, 
            facilitating data interpretation and analysis. These values are fundamental for understanding and processing digital imagery.

                <img src="assets/img/remote-sensing/pixel-values.gif" alt="" style="max-width: 100%; max-height: 100%;">

            Human vision perceives color through detecting the entire visible spectrum, and our brains process this information into distinct colors. In contrast, many sensors work by capturing 
            information within narrow wavelength ranges, storing it in channels or bands. Digital representation involves combining and displaying these channels using primary colors 
            (blue, green, and red). Each channel's data is represented by one of these colors, and the relative brightness (digital value) of each pixel in each channel determines the 
            final color by combining the primary colors in varying proportions. <p></p>

            <figure style="text-align: center;">
                <img src="assets/img/remote-sensing/the-pixels-1.png" alt="" style="max-width: 100%; max-height: 100%;">
                <figcaption style="text-align: center;"><strong>Image credit:</strong><a href="https://ieeexplore.ieee.org/document/6658949" target="_blank"> © Lefei Zhang et al.</a></figcaption>
            </figure>
          </section>

          <section id="Section-2">
            <h2>Satellite Characteristics: Orbits and Swaths </h2>
            <h4>Orbits:</h4>
            Satellites play a crucial role in various applications, including remote sensing, communication, and Earth observation. Two key characteristics defining satellite behavior are their orbits and swaths.
            <figure style="text-align: center;">
                <img src="assets/img/remote-sensing/orbit.png" alt="" style="max-width: 40%; max-height: 40%;">
                <figcaption style="text-align: center;"><strong>Image credit:</strong><a href="https://arunp77.github.io/Arun-Kumar-Pandey/" target="_blank"> © Arun Kumar Pandey.</a></figcaption>
            </figure>
            <ol>
                <li><strong>Low Earth Orbit (LEO):</strong>
                    <ul>
                        <li>Satellites in LEO orbit close to Earth, typically at altitudes ranging from about 180 to 2,000 kilometers.</li>
                        <li>LEO satellites offer advantages for remote sensing, providing high-resolution imagery and frequent revisits due to their shorter orbital periods.</li>
                        <li>Examples of LEO remote sensing satellites include the Landsat series and the International Space Station (ISS).</li>
                    </ul>
                </li>
            
                <li><strong>Medium Earth Orbit (MEO):</strong>
                    <ul>
                        <li>MEO satellites orbit at intermediate altitudes, typically between 2,000 and 35,786 kilometers.</li>
                        <li>These orbits provide a balance between coverage and resolution, making them suitable for a variety of applications, including navigation systems like GPS.</li>
                        <li>Examples of MEO satellites include those in the Global Navigation Satellite System (GNSS) constellations.</li>
                    </ul>
                </li>
            
                <li><strong>Geostationary Orbit (GEO):</strong>
                    <ul>
                        <li>GEO satellites are positioned at approximately 35,786 kilometers above the equator, allowing them to appear stationary relative to a fixed point on Earth.</li>
                        <li>These satellites provide continuous coverage of a specific region, making them ideal for applications like weather monitoring and communication.</li>
                        <li>Examples include weather satellites like GOES (Geostationary Operational Environmental Satellite).</li>
                    </ul>
                </li>
            
                <li><strong>Polar Orbit:</strong>
                    <ul>
                        <li>Satellites in polar orbits pass over Earth's poles, providing global coverage with each orbit.</li>
                        <li>These orbits are well-suited for Earth observation missions, as they cover the entire surface over time.</li>
                        <li>Examples include satellites from the Copernicus program, such as Sentinel-1 and Sentinel-2.</li>
                    </ul>
                </li>
            </ol>
            <h4>Swaths:</h4>
            The swath width refers to the coverage area on the Earth's surface captured by a satellite during a single pass. It is determined by the satellite's sensor characteristics and the 
            satellite's altitude. A wider swath allows for broader coverage but may sacrifice image resolution.

            Understanding the interplay between orbits and swaths is essential for optimizing satellite mission design. LEO satellites, for instance, may have smaller swaths but offer higher revisit 
            frequencies, making them suitable for applications requiring frequent observations. GEO satellites, on the other hand, have a fixed view but cover a larger area with each pass, making 
            them ideal for continuous monitoring.
            <figure style="text-align: center;">
                <img src="assets/img/remote-sensing/swath.png" alt="" style="max-width: 100%; max-height: 100%;">
                <figcaption style="text-align: center;"><strong>Image credit:</strong><a href="https://natural-resources.canada.ca/maps-tools-and-publications/satellite-imagery-and-air-photos/tutorial-fundamentals-remote-sensing/satellites-and-sensors/satellite-characteristics-orbits-and-swaths/9283" target="_blank"> © Remote Sensing Tutorials.</a></figcaption>
            </figure>

            <h3>Spatial Resolution, Pixel Size, and Scale</h3>
            <ul>
                <li>For some remote sensing instruments, the distance between the target being imaged and the platform, plays a large role in determining the detail of information obtained and the total area
                    imaged by the sensor. </li>
                <li>Sensors onboard platforms far away from their targets, typically view a larger area, but cannot provide great detail. The detail discernible in an image is dependent 
                    on the spatial resolution of the sensor and refers to the size of the smallest possible feature that can be detected. </li>
                <li><strong>Instantaneous Field of View (IFOV):</strong> Spatial resolution of passive sensors depends primarily on their IFOV.</li>
                    <ul>
                        <li><strong>Angular Cone of Visibility:</strong> IFOV is essentially the angular measurement (A) that defines the cone-shaped area within which a sensor can detect or "see" objects on the 
                            ground</li>
                        <li><strong>Dependent on Sensor Design:</strong> The IFOV is influenced by the design and optics of the sensor. It varies based on factors such as the focal length of the lens and the 
                            physical dimensions of the sensor.</li>
                        <li><strong>Spatial Resolution:</strong> IFOV has a direct impact on the spatial resolution of the imagery. A smaller IFOV results in higher spatial resolution, allowing the sensor to 
                            discern finer details in the captured scene.</li>
                        <li><strong>Calculation:</strong> The size of the ground area corresponding to a single pixel is determined by multiplying the IFOV by the distance from the sensor to the ground.</li>
                        <li><strong>Resolution Cell:</strong> The area on the ground corresponding to the IFOV is often referred to as a resolution cell. It represents the smallest unit of the scene that can 
                            be individually detected and recorded by the sensor.</li>
                        <li><strong>Application:</strong> Understanding IFOV is crucial for optimizing the design and performance of remote sensing systems. It influences decisions related to sensor 
                            specifications, altitude, and the overall capability to capture detailed information in the imagery.</li>
                    </ul>
                    <img src="assets/img/remote-sensing/IFOV.png" alt="" style="max-width: 50%; max-height: 50%;">
            
                <li>Images where only large features are visible are said to have coarse or low resolution. In fine or high resolution images, small objects can be detected.</li>
            </ul>
              
            <h3>Spectral Resolution </h3>
            Spectral resolution refers to a sensor's ability to distinguish between different wavelengths or bands of electromagnetic radiation in the electromagnetic 
            spectrum. It is a crucial aspect of remote sensing systems, influencing the capacity to capture and analyze various features on the Earth's surface.


          </section>





          





          <!-------------------------- Reference ------------------------------->
            <section id="reference">
                <h2>References</h2>
                <ul>
                    <li><a href="https://www.esa.int/SPECIALS/Eduspace_EN/SEM4HR3Z2OF_0.html" target="_blank">Analogue versus digital images.</a></li>
                    <li><a href="http://www.lmars.whu.edu.cn/prof_web/zhangliangpei/rs/publication/Hyperspectral%20Remote%20Sensing%20Image%20Subpixel.pdf" target="_blank">Hyperspectral Remote Sensing Image Subpixel
                        Target Detection Based on Supervised Metric Learning.</a></li>
                </ul>
            </section>

            <div class="navigation">
                <a href="portfolio-details-8.html" class="clickable-box">
                    <span class="arrow-left">Go Back</span>
                </a>
                <a href="Docker-Container.html" class="clickable-box">
                    <span class="arrow-right">Go to Docker Configuration</span>
                </a>
                <a href="Jupyter-nifi.html" class="clickable-box">
                <span class="arrow-right">Go to Jupyter & Nifi Configuration</span>
                </a>
            </div>

        </div>
    </section><!-- End Portfolio Details Section -->
</main><!-- End #main -->

<!-- ======= Footer ======= -->
<footer id="footer">
<div class="container">
  <div class="copyright">
    &copy; Copyright <strong><span>Arun</span></strong>
  </div>
  <div class="credits">
    <!-- All the links in the footer should remain intact. -->
    <!-- You can delete the links only if you purchased the pro version. -->
    <!-- Licensing information: https://bootstrapmade.com/license/ -->
    <!-- Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/iportfolio-bootstrap-portfolio-websites-template/ -->
    Designed by <a href="https://arunp77.github.io/Vision-Analytics/">Vision ANalytica</a>
  </div>
</div>
</footer><!-- End  Footer -->

<a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

<!-- Vendor JS Files -->
<script src="assets/vendor/purecounter/purecounter_vanilla.js"></script>
<script src="assets/vendor/aos/aos.js"></script>
<script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
<script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
<script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
<script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
<script src="assets/vendor/typed.js/typed.umd.js"></script>
<script src="assets/vendor/waypoints/noframework.waypoints.js"></script>
<script src="assets/vendor/php-email-form/validate.js"></script>

<!-- Template Main JS File -->
<script src="assets/js/main.js"></script>

<script>
document.addEventListener("DOMContentLoaded", function () {
  hljs.initHighlightingOnLoad();
});
</script>

</body>

</html>